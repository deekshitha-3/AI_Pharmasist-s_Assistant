{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70195f2b-9ae2-425c-9aa3-0fbcc6e7630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Reshape, Dense, LSTM, Bidirectional, BatchNormalization, Input, TimeDistributed, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "# Ensure Tesseract OCR is correctly configured\n",
    "pytesseract.pytesseract.tesseract_cmd = \"C://Program Files//Tesseract-OCR//tesseract.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f052dcc-3b18-4214-a489-ab09d8415376",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Paths\n",
    "DATASET_DIR = \"E:/Workspace/dataset/dataset/training/prescriptions\"\n",
    "LABELS_FILE = \"E:/Workspace/dataset/dataset/training/prescriptions/_annotations.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7380df73-de19-4c65-a32f-131ad717245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "labels_df = pd.read_csv(LABELS_FILE)\n",
    "labels_df.dropna(inplace=True)  # Remove missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1286999a-e77c-4366-99dd-5aeec1e8f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR Text Extraction Function\n",
    "def extract_text(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    text = pytesseract.image_to_string(img, config='--psm 6')\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1038a5a7-3c49-4eff-8ba2-105e97b80d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare images and text labels\n",
    "X, y = [], []\n",
    "for _, row in labels_df.iterrows():\n",
    "    image_path = os.path.join(DATASET_DIR, row[\"filename\"])\n",
    "    if os.path.exists(image_path):\n",
    "        img = load_img(image_path, color_mode='grayscale', target_size=(128, 128))\n",
    "        img = img_to_array(img) / 255.0\n",
    "        X.append(img)\n",
    "        y.append(extract_text(image_path))\n",
    "\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dff40d10-961c-4e2b-bef8-ae16fc08f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert text labels to numerical values\n",
    "tokenizer = Tokenizer(char_level=True, filters=\"\")\n",
    "tokenizer.fit_on_texts(y)\n",
    "y_seq = tokenizer.texts_to_sequences(y)\n",
    "max_length = max(len(seq) for seq in y_seq)\n",
    "y_padded = tf.keras.preprocessing.sequence.pad_sequences(y_seq, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d85287c5-e9c2-403d-876c-35f713414f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_padded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca24f619-d712-4ff6-b893-73a1369ddec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CNN+LSTM Model\n",
    "inputs = Input(shape=(128, 128, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c239e953-0acc-4aaa-ae98-6c9ec24b77be",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = BatchNormalization()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "64e5c111",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(x)  # Flatten before LSTM\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Ensure the reshaped shape maintains total element count\n",
    "if 512 % max_length == 0:\n",
    "    x = Reshape((max_length, 512 // max_length))(x)\n",
    "else:\n",
    "    x = Dense(max_length * 128, activation='relu')(x)  # Adjust dimensions\n",
    "    x = Reshape((max_length, 128))(x)  # Fixed reshape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3a86c731-7422-439c-b88d-7e6a9da1b758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape for LSTM\n",
    "x = Reshape((max_length, -1))(x)\n",
    "\n",
    "# BiLSTM layers\n",
    "x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "\n",
    "# Output layer\n",
    "x = TimeDistributed(Dense(len(tokenizer.word_index) + 1, activation='softmax'))(x)\n",
    "model = Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "df8e870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.cast(y_train, dtype=tf.int32)\n",
    "y_test = tf.cast(y_test, dtype=tf.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "900645f5-5917-49b9-bd83-5fbd07bfcea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, dtype=tf.int32)\n",
    "    batch_len = tf.shape(y_pred)[0]\n",
    "    input_len = tf.fill([batch_len], tf.shape(y_pred)[1])\n",
    "    label_len = tf.reduce_sum(tf.cast(tf.not_equal(y_true, 0), dtype=tf.int32), axis=1)\n",
    "\n",
    "    return tf.nn.ctc_loss(\n",
    "        labels=y_true,\n",
    "        logits=y_pred,\n",
    "        label_length=label_len,\n",
    "        logit_length=input_len,\n",
    "        logits_time_major=False,  # Ensure logits are batch-major\n",
    "        blank_index=len(tokenizer.word_index)  # Adjust blank index\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5a8b5829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=ctc_loss, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "25f03917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output shape: (None, 48, 77)\n",
      "y_train shape: (7267, 48)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model output shape: {model.output_shape}\")  # Expected: (None, ?, vocab_size)\n",
    "print(f\"y_train shape: {y_train.shape}\")  # Expected: (num_samples, ?, vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549f882d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "984e18aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 278ms/step - accuracy: 5.5779e-07 - loss: 160.8454 - val_accuracy: 0.0000e+00 - val_loss: 158.7991\n",
      "Epoch 2/20\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 265ms/step - accuracy: 8.4708e-06 - loss: 157.9327 - val_accuracy: 0.0000e+00 - val_loss: 158.7981\n",
      "Epoch 3/20\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 272ms/step - accuracy: 3.3045e-06 - loss: 158.0893 - val_accuracy: 0.0000e+00 - val_loss: 158.7977\n",
      "Epoch 4/20\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 276ms/step - accuracy: 7.2929e-06 - loss: 157.8031 - val_accuracy: 0.0000e+00 - val_loss: 158.7976\n",
      "Epoch 5/20\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 277ms/step - accuracy: 9.8342e-07 - loss: 157.7803 - val_accuracy: 0.0000e+00 - val_loss: 158.7975\n",
      "Epoch 6/20\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 280ms/step - accuracy: 1.3203e-06 - loss: 157.8851 - val_accuracy: 0.0000e+00 - val_loss: 158.7975\n",
      "Epoch 7/20\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 271ms/step - accuracy: 6.5053e-07 - loss: 158.1085 - val_accuracy: 0.0000e+00 - val_loss: 158.7974\n",
      "Epoch 8/20\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 281ms/step - accuracy: 3.8088e-07 - loss: 158.2991 - val_accuracy: 0.0000e+00 - val_loss: 158.7974\n",
      "Epoch 9/20\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 288ms/step - accuracy: 2.1969e-06 - loss: 158.0112 - val_accuracy: 0.0000e+00 - val_loss: 158.7974\n",
      "Epoch 10/20\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 290ms/step - accuracy: 3.5322e-06 - loss: 158.1125 - val_accuracy: 0.0000e+00 - val_loss: 158.7974\n",
      "Epoch 11/20\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 281ms/step - accuracy: 2.0756e-07 - loss: 157.8664 - val_accuracy: 0.0000e+00 - val_loss: 158.7974\n",
      "Epoch 12/20\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 280ms/step - accuracy: 4.7534e-07 - loss: 158.0903 - val_accuracy: 0.0000e+00 - val_loss: 158.7973\n",
      "Epoch 13/20\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 283ms/step - accuracy: 5.4262e-07 - loss: 157.7815 - val_accuracy: 0.0000e+00 - val_loss: 158.7973\n",
      "Epoch 14/20\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 290ms/step - accuracy: 3.4265e-06 - loss: 157.9375 - val_accuracy: 0.0000e+00 - val_loss: 158.7973\n",
      "Epoch 15/20\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 274ms/step - accuracy: 1.4628e-06 - loss: 157.6033 - val_accuracy: 0.0000e+00 - val_loss: 158.7973\n",
      "Epoch 16/20\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 271ms/step - accuracy: 3.7797e-06 - loss: 157.6780 - val_accuracy: 0.0000e+00 - val_loss: 158.7973\n",
      "Epoch 17/20\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 275ms/step - accuracy: 5.6778e-06 - loss: 157.5088 - val_accuracy: 0.0000e+00 - val_loss: 158.7973\n",
      "Epoch 18/20\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 275ms/step - accuracy: 3.3045e-06 - loss: 158.0279 - val_accuracy: 0.0000e+00 - val_loss: 158.7973\n",
      "Epoch 19/20\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 265ms/step - accuracy: 4.1684e-07 - loss: 157.7627 - val_accuracy: 0.0000e+00 - val_loss: 158.7973\n",
      "Epoch 20/20\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 271ms/step - accuracy: 3.4895e-06 - loss: 157.9231 - val_accuracy: 0.0000e+00 - val_loss: 158.7973\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=20, batch_size=16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5261f2dd-3377-44f4-9285-d86653de7ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
