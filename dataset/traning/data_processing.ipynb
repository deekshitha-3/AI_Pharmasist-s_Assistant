{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70195f2b-9ae2-425c-9aa3-0fbcc6e7630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Reshape, Dense, Dropout, LSTM, Bidirectional, BatchNormalization, Input, TimeDistributed\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.backend import ctc_batch_cost\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd =\"C://Program Files//Tesseract-OCR//tesseract.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f052dcc-3b18-4214-a489-ab09d8415376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATASET_DIR = \"C:/Users/deeks/Desktop/Engineering/GGH/Project/dataset/training/prescriptions\"\n",
    "LABELS_FILE = \"C:/Users/deeks/Desktop/Engineering/GGH/Project/dataset/training/prescriptions/_annotations.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7380df73-de19-4c65-a32f-131ad717245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "labels_df = pd.read_csv(LABELS_FILE)\n",
    "labels_df.dropna(inplace=True)  # Ensure no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1286999a-e77c-4366-99dd-5aeec1e8f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text using OCR\n",
    "def extract_text(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (128, 128))  # Resize for consistency\n",
    "    text = pytesseract.image_to_string(img, config='--psm 6')  # OCR extraction\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1038a5a7-3c49-4eff-8ba2-105e97b80d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Extracted\n"
     ]
    }
   ],
   "source": [
    "# Prepare images and extract text labels\n",
    "X, y = [], []\n",
    "for _, row in labels_df.iterrows():\n",
    "    image_path = os.path.join(DATASET_DIR, row[\"filename\"])\n",
    "    if os.path.exists(image_path):\n",
    "        img = load_img(image_path, color_mode='grayscale', target_size=(128, 128))\n",
    "        img = img_to_array(img) / 255.0  # Normalize\n",
    "        X.append(img)\n",
    "        extracted_text = extract_text(image_path)\n",
    "        y.append(extracted_text)\n",
    "\n",
    "X = np.array(X)\n",
    "print(\"Text Extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dff40d10-961c-4e2b-bef8-ae16fc08f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text labels to numerical values using Tokenization\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(char_level=True, filters=\"\")\n",
    "tokenizer.fit_on_texts(y)\n",
    "y_seq = tokenizer.texts_to_sequences(y)\n",
    "max_length = max([len(seq) for seq in y_seq])\n",
    "y_padded = tf.keras.preprocessing.sequence.pad_sequences(y_seq, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d85287c5-e9c2-403d-876c-35f713414f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_padded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca24f619-d712-4ff6-b893-73a1369ddec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CNN+LSTM OCR Model\n",
    "inputs = Input(shape=(128, 128, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c239e953-0acc-4aaa-ae98-6c9ec24b77be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Layers\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)  \n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)  \n",
    "x = BatchNormalization()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a86c731-7422-439c-b88d-7e6a9da1b758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN output shape before reshape: (None, 16, 16, 128)\n"
     ]
    }
   ],
   "source": [
    "# Reshape for LSTM\n",
    "shape_before_reshape = tf.keras.backend.int_shape(x)\n",
    "print(\"CNN output shape before reshape:\", shape_before_reshape)\n",
    "\n",
    "# Ensure shape has enough dimensions\n",
    "if len(shape_before_reshape) == 4:  # Expected (batch, H, W, C)\n",
    "    H, W, C = shape_before_reshape[1], shape_before_reshape[2], shape_before_reshape[3]\n",
    "    timesteps = H * W  # Flatten spatial dimensions\n",
    "    feature_dim = C\n",
    "    x = Reshape((timesteps, feature_dim))(x)  # âœ… Reshape correctly\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Unexpected CNN output shape: {shape_before_reshape}\")\n",
    "\n",
    "# LSTM Layers\n",
    "x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "900645f5-5917-49b9-bd83-5fbd07bfcea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully Connected Output Layer\n",
    "x = TimeDistributed(Dense(len(tokenizer.word_index) + 1, activation='softmax'))(x)\n",
    "\n",
    "model = Model(inputs, x)  # Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4194634a-2734-4278-aef2-b07fae2835cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CTC loss\n",
    "def ctc_loss(y_true, y_pred):\n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype='int64')\n",
    "    input_len = tf.fill([batch_len], tf.shape(y_pred)[1])\n",
    "    label_len = tf.reduce_sum(tf.cast(tf.not_equal(y_true, 0), dtype='int64'), axis=1)  # Actual label lengths\n",
    "    return ctc_batch_cost(y_true, y_pred, input_len, label_len)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=ctc_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d39bfc5-8188-48f6-9c45-cf216ecee5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\Engineering\\GGH\\Project\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[37], line 6\u001b[0m, in \u001b[0;36mctc_loss\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m      4\u001b[0m input_len \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfill([batch_len], tf\u001b[38;5;241m.\u001b[39mshape(y_pred)[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      5\u001b[0m label_len \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_sum(tf\u001b[38;5;241m.\u001b[39mcast(tf\u001b[38;5;241m.\u001b[39mnot_equal(y_true, \u001b[38;5;241m0\u001b[39m), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Actual label lengths\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mctc_batch_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_len\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5261f2dd-3377-44f4-9285-d86653de7ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
